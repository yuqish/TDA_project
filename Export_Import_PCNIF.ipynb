{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1707184-006f-4827-9ed3-d4362ae87ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "inf=float(\"inf\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "import stablerank.srank as sr\n",
    "import stablerank.geometry_objects_2020 as ge\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import _pickle as pickle\n",
    "import csv\n",
    "\n",
    "from ripser import ripser\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "\n",
    "from PIL import Image\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f093791-f45e-48f2-aca8-5f03fa74cddc",
   "metadata": {},
   "source": [
    "### Import Training Data - Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "436b31f9-882e-47d7-8164-605914fa0f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.read_csv('challenges-in-representation-learning-facial-expression-recognition-challenge/icml_face_data.csv', sep=',')\n",
    "df=pd.read_csv('challenges-in-representation-learning-facial-expression-recognition-challenge/train.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8e8ebfe-79fd-4ce2-9d4e-5e4f00e3728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicate values and reindexing\n",
    "df.drop_duplicates(subset =[\"pixels\"], inplace = True)\n",
    "df=df.reindex(range(0,len(df)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7316652d-d22d-46dd-b3f5-42d79b223456",
   "metadata": {},
   "source": [
    "### Import Test Data - Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b80a3459-b226-4c62-917c-c03baee9f8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('challenges-in-representation-learning-facial-expression-recognition-challenge/test.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5818f4d2-1ada-4d64-8e86-802d40ea2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicate values and reindexing\n",
    "df.drop_duplicates(subset =[\"pixels\"], inplace = True)\n",
    "df=df.reindex(range(0,len(df)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a223ca4-c891-4fce-bd91-64ede88d432f",
   "metadata": {},
   "source": [
    "## Try for one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e261f02b-1423-4572-809f-293ea077e8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first picture as an example\n",
    "pixel_values = [int(numeric_string) for numeric_string in df[\"pixels\"][3].split(' ')]\n",
    "\n",
    "image_dummy = np.empty((48*48,3), int)\n",
    "for i in range(0,len(image_dummy)):\n",
    "    image_dummy[i] = [(100/47)*(i-i%48)/48, (100/47)*(i%48), (100/47)*(47*pixel_values[i]/255)]\n",
    "\n",
    "image_stacked = np.vstack(image_dummy)\n",
    "image = sr.EucObject(image_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73b4e432-4d17-4ba3-a3d5-6e8a63e6799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 300\n",
    "degree=\"H1\"\n",
    "md=1\n",
    "\n",
    "# Compute the stable rank as above\n",
    "pixel_values_ti = [int(numeric_string) for numeric_string in df[\"pixels\"][index].split(' ')]\n",
    "image_dummy_ti = np.empty((48*48,3), int)\n",
    "for i in range(0,len(image_dummy_ti)):\n",
    "    image_dummy_ti[i] = [(100/47)*(i-i%48)/48, (100/47)*(i%48), (100/47)*(47*pixel_values_ti[i]/255)]\n",
    "\n",
    "image_stacked_ti = np.vstack(image_dummy_ti)\n",
    "image_ti = sr.EucObject(image_stacked_ti)\n",
    "\n",
    "b_ti = image.get_bc(maxdim=md)\n",
    "S_ti = sr.bc_to_sr(b_ti, degree)\n",
    "\n",
    "content = S_ti.content\n",
    "\n",
    "contents_1 = []\n",
    "contents_1.append(content[0])\n",
    "\n",
    "contents_2 = []\n",
    "contents_2.append(content[1])\n",
    "\n",
    "indeces = []\n",
    "indeces.append(index)\n",
    "\n",
    "data_test = {'old index':indeces, 'content 1':contents_1, 'content 2':contents_2}\n",
    "df_out_test = pd.DataFrame(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6aa790d5-1d80-4237-9940-e15cc599c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out_test.to_csv(\"Results/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "121dc379-54e0-48bc-8e42-4a0e3440d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reload=pd.read_csv(\"Results/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f160d150-5f50-488c-92b5-bb8d0cb820a1",
   "metadata": {},
   "source": [
    "### Reconstructing the PCNIF from the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b50e3220-f992-4328-b49c-51c7e117bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_temp = df_reload[\"content 1\"][0]\n",
    "c1 = [float(x) for x in c1_temp[1:-1].split()]\n",
    "c2_temp = df_reload[\"content 2\"][0]\n",
    "c2 = [float(x) for x in c2_temp[1:-1].split()]\n",
    "ce = [c1, c2]\n",
    "#### Result\n",
    "res = sr.Pcnif(ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d771d0b3-0581-4852-9cab-500bf8458610",
   "metadata": {},
   "source": [
    "## Exporting for one emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a7eae73-973b-4142-a60d-0f7ee3b4c744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting one emotion\n",
    "e = 3\n",
    "#0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n",
    "\n",
    "# specifying the number of pictures for subsampling\n",
    "number_of_pictures = 100\n",
    "\n",
    "# select homology and maxdim\n",
    "degree=\"H0\"\n",
    "md=0\n",
    "\n",
    "# Set up empty arrays for the indices and contents\n",
    "indices = []\n",
    "contents_1 = []\n",
    "contents_2 = []\n",
    "\n",
    "# Select random images for subsampling for emotion e\n",
    "pos = np.array(np.where(df[\"emotion\"]==e))[0]\n",
    "rand_pos = pos[list(np.random.permutation(np.arange(0,len(pos)-1))[:number_of_pictures])]\n",
    "    \n",
    "# Calculate stable ranks\n",
    "for l in range(0,number_of_pictures):\n",
    "    pixel_values_it = [int(numeric_string) for numeric_string in df[\"pixels\"][rand_pos[l]].split(' ')]\n",
    "    image_dummy_it = np.empty((48*48,3), int)\n",
    "    for i in range(0,len(image_dummy_it)):\n",
    "        image_dummy_it[i] = [(100/47)*(i-i%48)/48, (100/47)*(i%48), (100/47)*(47*pixel_values_it[i]/255)]\n",
    "\n",
    "    image_stacked_it = np.vstack(image_dummy_it)\n",
    "    image_it = sr.EucObject(image_stacked_it)\n",
    "\n",
    "    b_it = image_it.get_bc(maxdim=md)\n",
    "    S_it = sr.bc_to_sr(b_it, degree)\n",
    "    \n",
    "    content = S_it.content\n",
    "    \n",
    "    indices.append(rand_pos[l])\n",
    "    contents_1.append(content[0])\n",
    "    contents_2.append(content[1])\n",
    "    \n",
    "data = {'old index':indices, 'content 1':contents_1, 'content 2':contents_2}\n",
    "df_out = pd.DataFrame(data)\n",
    "df_out.to_csv(\"Results/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
